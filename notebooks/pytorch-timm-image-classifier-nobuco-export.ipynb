{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e4ba53",
   "metadata": {},
   "source": [
    "## Setting Up Your Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4d8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Install PyTorch with CUDA\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# # Install additional dependencies\n",
    "# !pip install pandas nobuco tensorflowjs\n",
    "\n",
    "# # Install utility packages\n",
    "# !pip install cjm_yolox_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6621d",
   "metadata": {},
   "source": [
    "## Importing the Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c591f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:01:18.984731: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-26 12:01:19.010130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 12:01:19.553434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import Python Standard Library dependencies\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Import timm library\n",
    "import timm\n",
    "\n",
    "# Import PyTorch dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import Nobuco dependencies\n",
    "from nobuco import pytorch_to_keras, ChannelOrder\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import TensorFlow.js dependencies\n",
    "from tensorflowjs import converters, quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4ed55-63b8-4ff8-a186-044ac30ed859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "119a139d-3575-407c-b06e-fad396ceefb0",
   "metadata": {},
   "source": [
    "## Setting Up the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6bb0d4-5498-446b-941f-bdc9d58b9fb0",
   "metadata": {},
   "source": [
    "### Set the Directory Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b24c2f-21f8-416d-9bc2-c95c89ab05de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3ad56\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ad56_level0_row0\" class=\"row_heading level0 row0\" >Project Directory:</th>\n",
       "      <td id=\"T_3ad56_row0_col0\" class=\"data row0 col0\" >pytorch-timm-image-classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ad56_level0_row1\" class=\"row_heading level0 row1\" >Checkpoint Directory:</th>\n",
       "      <td id=\"T_3ad56_row1_col0\" class=\"data row1 col0\" >pytorch-timm-image-classifier/2023-08-12_15-21-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc9e1437610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The name for the project\n",
    "project_name = f\"pytorch-timm-image-classifier\"\n",
    "\n",
    "# The path for the project folder\n",
    "project_dir = Path(f\"./{project_name}/\")\n",
    "\n",
    "# Create the project directory if it does not already exist\n",
    "project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# The path to the checkpoint folder\n",
    "checkpoint_dir = Path(project_dir/f\"2023-08-12_15-21-16\")\n",
    "\n",
    "pd.Series({\n",
    "    \"Project Directory:\": project_dir,\n",
    "    \"Checkpoint Directory:\": checkpoint_dir,\n",
    "}).to_frame().style.hide(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34899fe-c9b4-4a42-9cc2-99e683757ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7e7cfb-f258-47aa-9b1d-bcac4e1c7aba",
   "metadata": {},
   "source": [
    "## Loading the Checkpoint Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6e00a",
   "metadata": {},
   "source": [
    "### Load the Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8058d942-9b2c-4aa8-a605-01f12bc89080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dislike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no_gesture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>palm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>peace_inverted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stop_inverted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>three2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>two_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>two_up_inverted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0              call\n",
       "1           dislike\n",
       "2              fist\n",
       "3              four\n",
       "4              like\n",
       "5              mute\n",
       "6        no_gesture\n",
       "7                ok\n",
       "8               one\n",
       "9              palm\n",
       "10            peace\n",
       "11   peace_inverted\n",
       "12             rock\n",
       "13             stop\n",
       "14    stop_inverted\n",
       "15            three\n",
       "16           three2\n",
       "17           two_up\n",
       "18  two_up_inverted"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The class labels path\n",
    "class_labels_path = list(checkpoint_dir.glob('*classes.json'))[0]\n",
    "\n",
    "# Load the JSON class labels data\n",
    "with open(class_labels_path, 'r') as file:\n",
    "        class_labels_json = json.load(file)\n",
    "\n",
    "# Get the list of classes\n",
    "class_names = class_labels_json['classes']\n",
    "\n",
    "# Print the list of classes\n",
    "pd.DataFrame(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0058a-e511-472b-99ec-e0c67fd8230c",
   "metadata": {},
   "source": [
    "### Load the Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbf9b68-6e19-4e59-b928-e4136f384309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model checkpoint path\n",
    "checkpoint_path = list(checkpoint_dir.glob('*.pth'))[0]\n",
    "\n",
    "# Load the model checkpoint onto the CPU\n",
    "model_checkpoint = torch.load(checkpoint_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5bc7a-c0d1-4008-9de0-562eef8f880d",
   "metadata": {},
   "source": [
    "### Load the Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cf5fc9-12af-4e6c-8e16-6ee182213394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model configuration\n",
    "model_type = checkpoint_path.stem\n",
    "\n",
    "# Create a model with the number of output classes equal to the number of class names\n",
    "model = timm.create_model(model_type, num_classes=len(class_names))\n",
    "\n",
    "# Initialize the model with the checkpoint parameters and buffers\n",
    "model.load_state_dict(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577adf1",
   "metadata": {},
   "source": [
    "### Get the Normalization Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb6daf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the resnet module\n",
    "from timm.models import resnet\n",
    "\n",
    "# Get the default configuration of the chosen model\n",
    "model_cfg = resnet.default_cfgs[model_type].default.to_dict()\n",
    "\n",
    "# Retrieve normalization statistics (mean and std) specific to the pretrained model\n",
    "mean, std = model_cfg['mean'], model_cfg['std']\n",
    "norm_stats = (mean, std)\n",
    "norm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a921887-b147-469f-94e2-64b5ab91ca52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f08cb35-f9a8-49e8-8a4a-b52302736b59",
   "metadata": {},
   "source": [
    "## Converting the Model to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bb109-6471-4f94-ac7b-3e670c0ef89b",
   "metadata": {},
   "source": [
    "### Prepare the Model for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d01a9",
   "metadata": {},
   "source": [
    "#### Define model export wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc69e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceWrapper(nn.Module):\n",
    "    def __init__(self, model, normalize_mean, normalize_std, scale_inp=False, channels_last=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.register_buffer(\"normalize_mean\", normalize_mean)\n",
    "        self.register_buffer(\"normalize_std\", normalize_std)\n",
    "        self.scale_inp = scale_inp\n",
    "        self.channels_last = channels_last\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        if self.scale_inp:\n",
    "            x = x / 255.0\n",
    "\n",
    "        if self.channels_last:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = (x - self.normalize_mean) / self.normalize_std\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess_input(x)\n",
    "        x = self.model(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f4e9f-8446-45b3-9f88-0b5c8017a9f5",
   "metadata": {},
   "source": [
    "#### Wrap model with preprocessing and post-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b124a7-922e-41cc-92d6-357b734fe598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization mean and standard deviation\n",
    "mean_tensor = torch.tensor(norm_stats[0]).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(norm_stats[1]).view(1, 3, 1, 1)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval();\n",
    "\n",
    "# Wrap the model with preprocessing and post-processing steps\n",
    "wrapped_model = InferenceWrapper(model, \n",
    "                                 mean_tensor, \n",
    "                                 std_tensor, \n",
    "                                 scale_inp=True, # Scale input values from the rang [0,255] to [0,1]\n",
    "                                 channels_last=True, # Have the model expect input in channels-last format\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2134764-0692-458f-bd58-ed4a9849040a",
   "metadata": {},
   "source": [
    "### Prepare the Input Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3d4475-2e46-4628-967e-0f496888ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f039d5-599f-42bd-bff1-56898df87533",
   "metadata": {},
   "source": [
    "### Convert the PyTorch Model to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b5d5244-5ea5-4198-98c0-81a51e1be2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:01:20.929978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 12:01:20.930215: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mInferenceWrapper[__main__]\u001b[0m(float32_0<1,256,256,3>\u001b[0m) -> float32_170<1,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_0<1,256,256,3>\u001b[0m, 255.0) -> float32_1<1,256,256,3>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_1<1,256,256,3>\u001b[0m, 0, 3, 1, 2) -> float32_2<1,3,256,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__sub__[torch.Tensor]\u001b[0m(float32_2<1,3,256,256>\u001b[0m, \u001b[4mfloat32_3<1,3,1,1>\u001b[0m) -> float32_4<1,3,256,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_4<1,3,256,256>\u001b[0m, \u001b[4mfloat32_5<1,3,1,1>\u001b[0m) -> float32_6<1,3,256,256>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mResNet[timm.models.resnet]\u001b[0m(float32_6<1,3,256,256>\u001b[0m) -> float32_169<1,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_6<1,3,256,256>\u001b[0m) -> float32_22<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_6<1,3,256,256>\u001b[0m) -> float32_8<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_6<1,3,256,256>\u001b[0m, float32_7<32,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_8<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_8<1,32,128,128>\u001b[0m) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_8<1,32,128,128>\u001b[0m, float32_9<32>\u001b[0m, float32_10<32>\u001b[0m, float32_11<32>\u001b[0m, float32_12<32>\u001b[0m, False, 0.1, 1e-05) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_8<1,32,128,128>\u001b[0m, float32_11<32>\u001b[0m, float32_12<32>\u001b[0m, float32_9<32>\u001b[0m, float32_10<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_13<1,32,128,128>\u001b[0m) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_13<1,32,128,128>\u001b[0m, inplace=True) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_13<1,32,128,128>\u001b[0m) -> float32_13<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_13<1,32,128,128>\u001b[0m) -> float32_15<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_13<1,32,128,128>\u001b[0m, float32_14<32,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_15<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_15<1,32,128,128>\u001b[0m) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_15<1,32,128,128>\u001b[0m, float32_16<32>\u001b[0m, float32_17<32>\u001b[0m, float32_18<32>\u001b[0m, float32_19<32>\u001b[0m, False, 0.1, 1e-05) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_15<1,32,128,128>\u001b[0m, float32_18<32>\u001b[0m, float32_19<32>\u001b[0m, float32_16<32>\u001b[0m, float32_17<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_20<1,32,128,128>\u001b[0m) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_20<1,32,128,128>\u001b[0m, inplace=True) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_20<1,32,128,128>\u001b[0m) -> float32_20<1,32,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_20<1,32,128,128>\u001b[0m) -> float32_22<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_20<1,32,128,128>\u001b[0m, float32_21<64,32,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_22<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_22<1,64,128,128>\u001b[0m) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_22<1,64,128,128>\u001b[0m, float32_23<64>\u001b[0m, float32_24<64>\u001b[0m, float32_25<64>\u001b[0m, float32_26<64>\u001b[0m, False, 0.1, 1e-05) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_22<1,64,128,128>\u001b[0m, float32_25<64>\u001b[0m, float32_26<64>\u001b[0m, float32_23<64>\u001b[0m, float32_24<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_27<1,64,128,128>\u001b[0m) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_27<1,64,128,128>\u001b[0m, inplace=True) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_27<1,64,128,128>\u001b[0m) -> float32_27<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_27<1,64,128,128>\u001b[0m) -> float32_28<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mmax_pool2d[torch.nn.functional]\u001b[0m(float32_27<1,64,128,128>\u001b[0m, 3, 2, 1, 1, ceil_mode=False, return_indices=False) -> float32_28<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch]\u001b[0m(float32_27<1,64,128,128>\u001b[0m, 3, 2, 1, 1, False) -> float32_28<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_28<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_28<1,64,64,64>\u001b[0m) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_28<1,64,64,64>\u001b[0m) -> float32_30<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_28<1,64,64,64>\u001b[0m, float32_29<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_30<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_30<1,64,64,64>\u001b[0m) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_30<1,64,64,64>\u001b[0m, float32_31<64>\u001b[0m, float32_32<64>\u001b[0m, float32_33<64>\u001b[0m, float32_34<64>\u001b[0m, False, 0.1, 1e-05) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_30<1,64,64,64>\u001b[0m, float32_33<64>\u001b[0m, float32_34<64>\u001b[0m, float32_31<64>\u001b[0m, float32_32<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_35<1,64,64,64>\u001b[0m) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_35<1,64,64,64>\u001b[0m) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_35<1,64,64,64>\u001b[0m, inplace=True) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_35<1,64,64,64>\u001b[0m) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_35<1,64,64,64>\u001b[0m) -> float32_35<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_35<1,64,64,64>\u001b[0m) -> float32_37<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_35<1,64,64,64>\u001b[0m, float32_36<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_37<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_37<1,64,64,64>\u001b[0m) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_37<1,64,64,64>\u001b[0m, float32_38<64>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, float32_41<64>\u001b[0m, False, 0.1, 1e-05) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_37<1,64,64,64>\u001b[0m, float32_40<64>\u001b[0m, float32_41<64>\u001b[0m, float32_38<64>\u001b[0m, float32_39<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_42<1,64,64,64>\u001b[0m, float32_28<1,64,64,64>\u001b[0m) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_42<1,64,64,64>\u001b[0m) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_42<1,64,64,64>\u001b[0m, inplace=True) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_42<1,64,64,64>\u001b[0m) -> float32_42<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_42<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_42<1,64,64,64>\u001b[0m) -> float32_44<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_42<1,64,64,64>\u001b[0m, float32_43<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_44<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_44<1,64,64,64>\u001b[0m) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_44<1,64,64,64>\u001b[0m, float32_45<64>\u001b[0m, float32_46<64>\u001b[0m, float32_47<64>\u001b[0m, float32_48<64>\u001b[0m, False, 0.1, 1e-05) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_44<1,64,64,64>\u001b[0m, float32_47<64>\u001b[0m, float32_48<64>\u001b[0m, float32_45<64>\u001b[0m, float32_46<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_49<1,64,64,64>\u001b[0m) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_49<1,64,64,64>\u001b[0m) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_49<1,64,64,64>\u001b[0m, inplace=True) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_49<1,64,64,64>\u001b[0m) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_49<1,64,64,64>\u001b[0m) -> float32_49<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_49<1,64,64,64>\u001b[0m) -> float32_51<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_49<1,64,64,64>\u001b[0m, float32_50<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_51<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_51<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_51<1,64,64,64>\u001b[0m, float32_52<64>\u001b[0m, float32_53<64>\u001b[0m, float32_54<64>\u001b[0m, float32_55<64>\u001b[0m, False, 0.1, 1e-05) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_51<1,64,64,64>\u001b[0m, float32_54<64>\u001b[0m, float32_55<64>\u001b[0m, float32_52<64>\u001b[0m, float32_53<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_56<1,64,64,64>\u001b[0m, float32_42<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_56<1,64,64,64>\u001b[0m, inplace=True) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_56<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_58<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_56<1,64,64,64>\u001b[0m, float32_57<128,64,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_58<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_58<1,128,32,32>\u001b[0m) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_58<1,128,32,32>\u001b[0m, float32_59<128>\u001b[0m, float32_60<128>\u001b[0m, float32_61<128>\u001b[0m, float32_62<128>\u001b[0m, False, 0.1, 1e-05) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_58<1,128,32,32>\u001b[0m, float32_61<128>\u001b[0m, float32_62<128>\u001b[0m, float32_59<128>\u001b[0m, float32_60<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_63<1,128,32,32>\u001b[0m) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_63<1,128,32,32>\u001b[0m) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_63<1,128,32,32>\u001b[0m, inplace=True) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_63<1,128,32,32>\u001b[0m) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_63<1,128,32,32>\u001b[0m) -> float32_63<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_63<1,128,32,32>\u001b[0m) -> float32_65<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_63<1,128,32,32>\u001b[0m, float32_64<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_65<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_65<1,128,32,32>\u001b[0m) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_65<1,128,32,32>\u001b[0m, float32_66<128>\u001b[0m, float32_67<128>\u001b[0m, float32_68<128>\u001b[0m, float32_69<128>\u001b[0m, False, 0.1, 1e-05) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_65<1,128,32,32>\u001b[0m, float32_68<128>\u001b[0m, float32_69<128>\u001b[0m, float32_66<128>\u001b[0m, float32_67<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_78<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_56<1,64,64,64>\u001b[0m) -> float32_71<1,64,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_56<1,64,64,64>\u001b[0m, 2, 2, 0, True, False, None) -> float32_71<1,64,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,64,32,32>\u001b[0m) -> float32_73<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,64,32,32>\u001b[0m, float32_72<128,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_73<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_73<1,128,32,32>\u001b[0m) -> float32_78<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_73<1,128,32,32>\u001b[0m, float32_74<128>\u001b[0m, float32_75<128>\u001b[0m, float32_76<128>\u001b[0m, float32_77<128>\u001b[0m, False, 0.1, 1e-05) -> float32_78<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_73<1,128,32,32>\u001b[0m, float32_76<128>\u001b[0m, float32_77<128>\u001b[0m, float32_74<128>\u001b[0m, float32_75<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_78<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_70<1,128,32,32>\u001b[0m, float32_78<1,128,32,32>\u001b[0m) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_70<1,128,32,32>\u001b[0m) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_70<1,128,32,32>\u001b[0m, inplace=True) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_70<1,128,32,32>\u001b[0m) -> float32_70<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_70<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_70<1,128,32,32>\u001b[0m) -> float32_80<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_70<1,128,32,32>\u001b[0m, float32_79<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_80<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_80<1,128,32,32>\u001b[0m) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_80<1,128,32,32>\u001b[0m, float32_81<128>\u001b[0m, float32_82<128>\u001b[0m, float32_83<128>\u001b[0m, float32_84<128>\u001b[0m, False, 0.1, 1e-05) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_80<1,128,32,32>\u001b[0m, float32_83<128>\u001b[0m, float32_84<128>\u001b[0m, float32_81<128>\u001b[0m, float32_82<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_85<1,128,32,32>\u001b[0m) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_85<1,128,32,32>\u001b[0m) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_85<1,128,32,32>\u001b[0m, inplace=True) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_85<1,128,32,32>\u001b[0m) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_85<1,128,32,32>\u001b[0m) -> float32_85<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_85<1,128,32,32>\u001b[0m) -> float32_87<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_85<1,128,32,32>\u001b[0m, float32_86<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_87<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_87<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_87<1,128,32,32>\u001b[0m, float32_88<128>\u001b[0m, float32_89<128>\u001b[0m, float32_90<128>\u001b[0m, float32_91<128>\u001b[0m, False, 0.1, 1e-05) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_87<1,128,32,32>\u001b[0m, float32_90<128>\u001b[0m, float32_91<128>\u001b[0m, float32_88<128>\u001b[0m, float32_89<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_92<1,128,32,32>\u001b[0m, float32_70<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_92<1,128,32,32>\u001b[0m, inplace=True) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_94<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_92<1,128,32,32>\u001b[0m, float32_93<256,128,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_94<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_94<1,256,16,16>\u001b[0m) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_94<1,256,16,16>\u001b[0m, float32_95<256>\u001b[0m, float32_96<256>\u001b[0m, float32_97<256>\u001b[0m, float32_98<256>\u001b[0m, False, 0.1, 1e-05) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_94<1,256,16,16>\u001b[0m, float32_97<256>\u001b[0m, float32_98<256>\u001b[0m, float32_95<256>\u001b[0m, float32_96<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_99<1,256,16,16>\u001b[0m) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_99<1,256,16,16>\u001b[0m) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_99<1,256,16,16>\u001b[0m, inplace=True) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_99<1,256,16,16>\u001b[0m) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_99<1,256,16,16>\u001b[0m) -> float32_99<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_99<1,256,16,16>\u001b[0m) -> float32_101<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_99<1,256,16,16>\u001b[0m, float32_100<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_101<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_101<1,256,16,16>\u001b[0m) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_101<1,256,16,16>\u001b[0m, float32_102<256>\u001b[0m, float32_103<256>\u001b[0m, float32_104<256>\u001b[0m, float32_105<256>\u001b[0m, False, 0.1, 1e-05) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_101<1,256,16,16>\u001b[0m, float32_104<256>\u001b[0m, float32_105<256>\u001b[0m, float32_102<256>\u001b[0m, float32_103<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_114<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_107<1,128,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_92<1,128,32,32>\u001b[0m, 2, 2, 0, True, False, None) -> float32_107<1,128,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_107<1,128,16,16>\u001b[0m) -> float32_109<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_107<1,128,16,16>\u001b[0m, float32_108<256,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_109<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_109<1,256,16,16>\u001b[0m) -> float32_114<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_109<1,256,16,16>\u001b[0m, float32_110<256>\u001b[0m, float32_111<256>\u001b[0m, float32_112<256>\u001b[0m, float32_113<256>\u001b[0m, False, 0.1, 1e-05) -> float32_114<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_109<1,256,16,16>\u001b[0m, float32_112<256>\u001b[0m, float32_113<256>\u001b[0m, float32_110<256>\u001b[0m, float32_111<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_114<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_106<1,256,16,16>\u001b[0m, float32_114<1,256,16,16>\u001b[0m) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_106<1,256,16,16>\u001b[0m) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_106<1,256,16,16>\u001b[0m, inplace=True) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_106<1,256,16,16>\u001b[0m) -> float32_106<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_106<1,256,16,16>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_106<1,256,16,16>\u001b[0m) -> float32_116<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_106<1,256,16,16>\u001b[0m, float32_115<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_116<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_116<1,256,16,16>\u001b[0m) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_116<1,256,16,16>\u001b[0m, float32_117<256>\u001b[0m, float32_118<256>\u001b[0m, float32_119<256>\u001b[0m, float32_120<256>\u001b[0m, False, 0.1, 1e-05) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_116<1,256,16,16>\u001b[0m, float32_119<256>\u001b[0m, float32_120<256>\u001b[0m, float32_117<256>\u001b[0m, float32_118<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_121<1,256,16,16>\u001b[0m) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_121<1,256,16,16>\u001b[0m) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_121<1,256,16,16>\u001b[0m, inplace=True) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_121<1,256,16,16>\u001b[0m) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_121<1,256,16,16>\u001b[0m) -> float32_121<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_121<1,256,16,16>\u001b[0m) -> float32_123<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_121<1,256,16,16>\u001b[0m, float32_122<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_123<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_123<1,256,16,16>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_123<1,256,16,16>\u001b[0m, float32_124<256>\u001b[0m, float32_125<256>\u001b[0m, float32_126<256>\u001b[0m, float32_127<256>\u001b[0m, False, 0.1, 1e-05) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_123<1,256,16,16>\u001b[0m, float32_126<256>\u001b[0m, float32_127<256>\u001b[0m, float32_124<256>\u001b[0m, float32_125<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_128<1,256,16,16>\u001b[0m, float32_106<1,256,16,16>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_128<1,256,16,16>\u001b[0m, inplace=True) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_128<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_130<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_128<1,256,16,16>\u001b[0m, float32_129<512,256,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_130<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_130<1,512,8,8>\u001b[0m) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_130<1,512,8,8>\u001b[0m, float32_131<512>\u001b[0m, float32_132<512>\u001b[0m, float32_133<512>\u001b[0m, float32_134<512>\u001b[0m, False, 0.1, 1e-05) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_130<1,512,8,8>\u001b[0m, float32_133<512>\u001b[0m, float32_134<512>\u001b[0m, float32_131<512>\u001b[0m, float32_132<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_135<1,512,8,8>\u001b[0m) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_135<1,512,8,8>\u001b[0m) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_135<1,512,8,8>\u001b[0m, inplace=True) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_135<1,512,8,8>\u001b[0m) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_135<1,512,8,8>\u001b[0m) -> float32_135<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_135<1,512,8,8>\u001b[0m) -> float32_137<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_135<1,512,8,8>\u001b[0m, float32_136<512,512,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_137<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_137<1,512,8,8>\u001b[0m) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_137<1,512,8,8>\u001b[0m, float32_138<512>\u001b[0m, float32_139<512>\u001b[0m, float32_140<512>\u001b[0m, float32_141<512>\u001b[0m, False, 0.1, 1e-05) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_137<1,512,8,8>\u001b[0m, float32_140<512>\u001b[0m, float32_141<512>\u001b[0m, float32_138<512>\u001b[0m, float32_139<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_150<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_128<1,256,16,16>\u001b[0m) -> float32_143<1,256,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mavg_pool2d[torch.nn.functional]\u001b[0m(float32_128<1,256,16,16>\u001b[0m, 2, 2, 0, True, False, None) -> float32_143<1,256,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_143<1,256,8,8>\u001b[0m) -> float32_145<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_143<1,256,8,8>\u001b[0m, float32_144<512,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_145<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_145<1,512,8,8>\u001b[0m) -> float32_150<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_145<1,512,8,8>\u001b[0m, float32_146<512>\u001b[0m, float32_147<512>\u001b[0m, float32_148<512>\u001b[0m, float32_149<512>\u001b[0m, False, 0.1, 1e-05) -> float32_150<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_145<1,512,8,8>\u001b[0m, float32_148<512>\u001b[0m, float32_149<512>\u001b[0m, float32_146<512>\u001b[0m, float32_147<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_150<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_142<1,512,8,8>\u001b[0m, float32_150<1,512,8,8>\u001b[0m) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_142<1,512,8,8>\u001b[0m) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_142<1,512,8,8>\u001b[0m, inplace=True) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_142<1,512,8,8>\u001b[0m) -> float32_142<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBasicBlock[timm.models.resnet]\u001b[0m(float32_142<1,512,8,8>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_142<1,512,8,8>\u001b[0m) -> float32_152<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_142<1,512,8,8>\u001b[0m, float32_151<512,512,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_152<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_152<1,512,8,8>\u001b[0m) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_152<1,512,8,8>\u001b[0m, float32_153<512>\u001b[0m, float32_154<512>\u001b[0m, float32_155<512>\u001b[0m, float32_156<512>\u001b[0m, False, 0.1, 1e-05) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_152<1,512,8,8>\u001b[0m, float32_155<512>\u001b[0m, float32_156<512>\u001b[0m, float32_153<512>\u001b[0m, float32_154<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_157<1,512,8,8>\u001b[0m) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_157<1,512,8,8>\u001b[0m) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_157<1,512,8,8>\u001b[0m, inplace=True) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_157<1,512,8,8>\u001b[0m) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mIdentity[torch.nn.modules.linear]\u001b[0m(float32_157<1,512,8,8>\u001b[0m) -> float32_157<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_157<1,512,8,8>\u001b[0m) -> float32_159<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_157<1,512,8,8>\u001b[0m, float32_158<512,512,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_159<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_159<1,512,8,8>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_159<1,512,8,8>\u001b[0m, float32_160<512>\u001b[0m, float32_161<512>\u001b[0m, float32_162<512>\u001b[0m, float32_163<512>\u001b[0m, False, 0.1, 1e-05) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_159<1,512,8,8>\u001b[0m, float32_162<512>\u001b[0m, float32_163<512>\u001b[0m, float32_160<512>\u001b[0m, float32_161<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_164<1,512,8,8>\u001b[0m, float32_142<1,512,8,8>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_164<1,512,8,8>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_164<1,512,8,8>\u001b[0m, inplace=True) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_164<1,512,8,8>\u001b[0m) -> float32_164<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSelectAdaptivePool2d[timm.layers.adaptive_avgmax_pool]\u001b[0m(float32_164<1,512,8,8>\u001b[0m) -> float32_166<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_164<1,512,8,8>\u001b[0m) -> float32_165<1,512,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_164<1,512,8,8>\u001b[0m, 1) -> float32_165<1,512,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mFlatten[torch.nn.modules.flatten]\u001b[0m(float32_165<1,512,1,1>\u001b[0m) -> float32_166<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mflatten[torch.Tensor]\u001b[0m(float32_165<1,512,1,1>\u001b[0m, 1, -1) -> float32_166<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_166<1,512>\u001b[0m) -> float32_169<1,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_166<1,512>\u001b[0m, float32_167<19,512>\u001b[0m, float32_168<19>\u001b[0m) -> float32_169<1,19>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_169<1,19>\u001b[0m) -> float32_170<1,19>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32msoftmax[torch.nn.functional]\u001b[0m(float32_169<1,19>\u001b[0m, 1, _stacklevel=5) -> float32_170<1,19>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.Tensor]\u001b[0m(float32_169<1,19>\u001b[0m, 1) -> float32_170<1,19>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 1.22 sec.\n"
     ]
    }
   ],
   "source": [
    "keras_model = pytorch_to_keras(\n",
    "    wrapped_model, \n",
    "    args=[input_tensor],\n",
    "    inputs_channel_order=ChannelOrder.PYTORCH,\n",
    "    outputs_channel_order=ChannelOrder.PYTORCH, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869c993-63f9-467f-a93f-0eef0dd0cd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb95ef2-d894-45c9-9512-e4b8d0f83bad",
   "metadata": {},
   "source": [
    "## Enabling Dynamic Input Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92059b14-06e1-4642-8a56-68ecb6c789d6",
   "metadata": {},
   "source": [
    "### Define New Input Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9049bd9-b40e-449a-9e08-0a8a40e050b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6328d\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6328d_level0_row0\" class=\"row_heading level0 row0\" >Source Input Shape:</th>\n",
       "      <td id=\"T_6328d_row0_col0\" class=\"data row0 col0\" >(256, 256, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6328d_level0_row1\" class=\"row_heading level0 row1\" >Dynamic Input Shape:</th>\n",
       "      <td id=\"T_6328d_row1_col0\" class=\"data row1 col0\" >(None, None, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc93046a210>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current input shape\n",
    "input_shape = keras_model.layers[0].input_shape[0][1:]\n",
    "\n",
    "# Make every dimension except the channel dimension dynamic\n",
    "dynamic_input_shape = tuple(i if i == 3 else None for i in input_shape)\n",
    "\n",
    "pd.Series({\n",
    "    \"Source Input Shape:\": input_shape,\n",
    "    \"Dynamic Input Shape:\": dynamic_input_shape,\n",
    "}).to_frame().style.hide(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defd0f3-241e-4a92-a517-9c8d2656896d",
   "metadata": {},
   "source": [
    "### Build Dynamic Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b24283d-399b-49c5-bbf3-0d3a57763f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.transpose), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(1, 3, 1, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.transpose_1), but are not present in its tracked objects:   <tf.Variable 'weight:0' shape=(1, 3, 1, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras tensor with the dynamic input shape\n",
    "inputs = tf.keras.Input(shape=dynamic_input_shape)\n",
    "# Get a Keras tensor with the dynamic output shape \n",
    "outputs = keras_model(inputs)\n",
    "\n",
    "# Build a Keras model with dynamic input and output shapes\n",
    "dynamic_model = tf.keras.Model(inputs, outputs)\n",
    "# Add the trained weights to the dynamic Keras model\n",
    "dynamic_model.set_weights(keras_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043240e-8b97-46e5-a8c8-1e49dde96085",
   "metadata": {},
   "source": [
    "### Save the Keras Model in SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1061c00f-252e-4a80-a696-a841f1103450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: pytorch-timm-image-classifier/2023-08-12_15-21-16/hagrid-classification-512p-no-gesture-150k-zip-resnet18d-tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pytorch-timm-image-classifier/2023-08-12_15-21-16/hagrid-classification-512p-no-gesture-150k-zip-resnet18d-tf/assets\n"
     ]
    }
   ],
   "source": [
    "# Set the folder path for the SavedModel files\n",
    "savedmodel_dir = Path(f\"{checkpoint_dir}/{class_labels_path.stem.removesuffix('-classes')}-{model_type}-tf\")\n",
    "# Save the TensorFlow model to disk\n",
    "dynamic_model.save(savedmodel_dir, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbc31b-9c7a-4028-9963-618f6c886b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4b878ce-d5d9-4ab9-874d-00346fc5f6ce",
   "metadata": {},
   "source": [
    "## Exporting the Model to TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c64608-6484-4cb8-a7f4-4b1db3075939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 12:01:34.786450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 12:01:34.786548: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-09-26 12:01:34.786623: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-09-26 12:01:34.786868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-26 12:01:34.786922: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Set the path for TensorFlow.js model files\n",
    "tfjs_model_dir = f\"{savedmodel_dir}js-uint8\"\n",
    "\n",
    "# Convert the TensorFlow SavedModel to a TensorFlow.js Graph model\n",
    "converters.convert_tf_saved_model(saved_model_dir=str(savedmodel_dir), \n",
    "                                  output_dir=tfjs_model_dir, \n",
    "                                  quantization_dtype_map={quantization.QUANTIZATION_DTYPE_UINT8:True}\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3688d-9308-4c24-8237-40a89e60d534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
